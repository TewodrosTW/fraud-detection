{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233fdf2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Load processed data\n",
    "X_train = np.load('data/processed/X_train_smote.npy')\n",
    "y_train = np.load('data/processed/y_train_smote.npy')\n",
    "X_test = np.load('data/processed/X_test.npy')\n",
    "y_test = np.load('data/processed/y_test.npy')\n",
    "\n",
    "# Load preprocessor (for feature names later)\n",
    "preprocessor = joblib.load('data/processed/preprocessor.pkl')\n",
    "\n",
    "print(\"✅ Data loaded for modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef6976",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline: Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_proba_lr = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "print(\"=== Logistic Regression (Baseline) ===\")\n",
    "print(f\"F1-Score: {f1_lr:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# AUC-PR\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_lr)\n",
    "auc_pr_lr = auc(recall, precision)\n",
    "print(f\"AUC-PR: {auc_pr_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b254df0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensemble: XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_proba_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(\"=== XGBoost (Ensemble) ===\")\n",
    "print(f\"F1-Score: {f1_xgb:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# AUC-PR\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba_xgb)\n",
    "auc_pr_xgb = auc(recall, precision)\n",
    "print(f\"AUC-PR: {auc_pr_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c991b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stratified K-Fold CV (k=5)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model_cv(model, X, y):\n",
    "    f1_scores = []\n",
    "    auc_pr_scores = []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "        p, r, _ = precision_recall_curve(y_val, y_proba)\n",
    "        auc_pr_scores.append(auc(r, p))\n",
    "    return np.mean(f1_scores), np.std(f1_scores), np.mean(auc_pr_scores), np.std(auc_pr_scores)\n",
    "\n",
    "# Evaluate both models\n",
    "f1_lr_mean, f1_lr_std, auc_pr_lr_mean, auc_pr_lr_std = evaluate_model_cv(lr, X_train, y_train)\n",
    "f1_xgb_mean, f1_xgb_std, auc_pr_xgb_mean, auc_pr_xgb_std = evaluate_model_cv(xgb, X_train, y_train)\n",
    "\n",
    "print(\"=== Cross-Validation Results (Mean ± Std) ===\")\n",
    "print(f\"Logistic Regression → F1: {f1_lr_mean:.4f} ± {f1_lr_std:.4f} | AUC-PR: {auc_pr_lr_mean:.4f} ± {auc_pr_lr_std:.4f}\")\n",
    "print(f\"XGBoost             → F1: {f1_xgb_mean:.4f} ± {f1_xgb_std:.4f} | AUC-PR: {auc_pr_xgb_mean:.4f} ± {auc_pr_xgb_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99df67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== MODEL SELECTION ===\")\n",
    "if auc_pr_xgb > auc_pr_lr:\n",
    "    print(\"✅ SELECTED MODEL: XGBoost\")\n",
    "    print(\"- Higher AUC-PR → better at ranking fraud cases\")\n",
    "    print(\"- F1-Score balanced → controls false positives/negatives\")\n",
    "    best_model = xgb\n",
    "else:\n",
    "    print(\"✅ SELECTED MODEL: Logistic Regression\")\n",
    "    print(\"- Interpretable (meets business trust needs)\")\n",
    "    best_model = lr\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, 'src/models/best_fraud_model.pkl')\n",
    "print(\"\\n✅ Best model saved to src/models/best_fraud_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
